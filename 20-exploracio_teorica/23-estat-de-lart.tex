\section{Estat de l'art}
En aquesta secció es revisa l'estat de l'art dels models que poden solucionar el problema plantejat. Per aconseguir la millor solució, s'ha proposat mantenir un rang de cerca ampli, i considerar moltes propostes que en un principi no havien sigut plantejades.
\subsection{Aplicacions comercials}
Lògicament, un model de generació del llenguatge natural pot ser una eina molt potent si es busca el propòsit adequat. És per això, que moltes empreses han decidit invertir en aquest sector per assolir aquests models tan potents. Aquests models són, generalment, l'estat de l'art en aquest àmbit, ja que disposen de molts recursos per obtenir el millor resultat possible. A continuació es presenten els models comercialitzats més importants en l'àmbit global:

\begin{itemize}
  \item \textbf{GPT-4:} \textit{GPT-4} és un gran model multimodal que pot agafar entrades d'imatge i text i produir sortides de text. Representa el darrer avenç en la investigació d'\textit{OpenAI} sobre l'ampliació del \textit{deep learning}. El seu principal ús és per crear xatbots (bots conversacionals) generals, que poden conversar sobre temes molt diversos i, fins i tot, cercar a la xarxa per aportar informació extra. Alguns exemples són \textit{ChatGPT} i \textit{Bing Chat}, tots dos són serveis en línia i, per tant, no aplicables per al projecte.
  \item \textbf{LaMDA:} \textit{LaMDA} és una col·lecció de grans models lingüístics desenvolupats per Google que treballen conjuntament per resoldre diverses tasques de generació de text. \textit{LaMDA} no està disponible públicament i només es pot accedir utilitzant la seva plataforma. Google va integrar aquest model en alguns dels seus productes, per millorar la seva funcionalitat i també va desenvolupar una primera versió d'un xatbot (\textit{Google Bard}) que durant un temps va usar aquest model.
  \item \textbf{PaLM 2:} \textit{PaLM 2} és un gran model lingüístic (LLM) que amplia el llegat de Google en matèria d'aprenentatge automàtic i de recerca responsable de la IA. S'ha entrenat en un corpus divers i multilingüe de text, codi, matemàtiques i pàgines web i va ser usat durant un temps com a xatbot amb \textit{Google Bard}. Tot i que no és de codi obert, es pot accedir a PaLM 2 a través d'una API.
  \item \textbf{Gemini:} \textit{Gemini} de Google és un ambiciós projecte d'intel·ligència artificial. És gran model de llenguatge (LLM) que tingui la capacitat de fer una gran varietat de tasques, incloses les relacionades amb text, imatges i àudio. \textit{Gemini} compta amb un disseny multimodal que permet la integració de diversos tipus d'informació i dona lloc a una àmplia gamma de formats de sortida. No és una plataforma de codi obert, per la qual cosa el codi i les dades no són accessibles al públic. Per altra banda, s'integra amb eines d'IA per a la generació de continguts, com ara la versió més nova de \textit{Google Bard}, que permet la interacció de l'usuari amb aquest model.
  \item \textbf{Claude 2:} \textit{Claude 2} és un model de llenguatge d'intel·ligència artificial avançat desenvolupat per \textit{Anthropic} amb un enfocament a IA segura i beneficiosa. Permet generar textos de primera qualitat i contextualment apropiats per a diverses aplicacions, com ara la generació de codi, l'anàlisi de textos i la redacció de composicions. És accessible al públic mitjançant un lloc web beta (en forma de xatbot), però el codi i les dades utilitzades per la formació i el funcionament no són accessibles pel públic.
  \item \textbf{Inflection-1:} \textit{Inflection-1} és un gran model de llenguatge (LLM) desenvolupat per \textit{Inflection AI}. És la base de \textit{Pi}, un assistent d'IA que pretén ser un xatbot de companyia, que continua les converses més llargues amb els usuaris i s'adapta a cadascun d'ells en funció d'aquestes converses. \textit{Inflection-1} no està disponible públicament i només és accessible en línia a través del xatbot que fa servir.
  \item \textbf{Grok-1:} \textit{Grok-1} va ser creat per \textit{xAI}. Es tracta del motor que impulsa \textit{Grok}, un xatbot capaç de respondre gairebé qualsevol dubte i fins i tot d'oferir suggeriments sobre les preguntes que s'han de formular. \textit{Grok} està configurat per assistir als usuaris amb la xarxa social que del que és propietari el mateix fundador de l'empresa. \textit{Grok-1} no és un model de codi obert i no es pot emprar de manera lliure a excepció d'una beta oberta.
\end{itemize}

\subsection{Propostes descartades}
El procés de selecció del model va exigir una avaluació acurada de múltiples candidats per garantir la seva adequació als objectius del projecte. El fet de considerar tants models, cadascun amb els seus punts forts i febles, ha implicat inevitablement un rebuig de molts d'ells per trobar la solució que millor s'adeqüi al problema. 

Seguint aquestes directrius, s'ha intentat aconseguir una avaluació exhaustiva i imparcial dels models candidats. En última instància, s'han triat les opcions més adequades per complir els objectius del projecte, alhora que es treballa dins de les limitacions imposades per la sensibilitat de les dades i els recursos computacionals. La secció següent aprofundeix en les raons que van portar a descartar determinats models durant la fase de recerca.

\subsubsection{Resolució inadequada d'extreure informació}
Un dels principals criteris de selecció d'un model ha sigut la seva capacitat per extreure les paraules adequades del text que se li ofereix. Els models que no han complert una prova base que representa l'ús que se li donarà al model són exclosos immediatament. 

La prova en qüestió es basa en, donat un tiquet d'exemple, fer una pregunta o formular una frase, de manera que la continuació sempre sigui una frase que estigui continguda en el text. Aquesta prova s'ha modificat depenent de per quina tasca està entrenat cada model. Això ha servit per descartar directament els models menys adequats i quedar-se amb el que són capaços de contestar correctament, permetent entrenar només aquells que ja anaven encaminats.

\subsubsection{Accessibilitat en línia i restriccions dels acords de confidencialitat}
Alguns models han sigut eliminats a causa de la seva accessibilitat només en línia, cosa que no s'ajusta al marc del projecte, que requereix un funcionament \textit{in situ} sense dependència de servidors externs. És inviable emprar models que exigeixin la transferència de dades fora dels servidors controlats, atesa la sensibilitat de les dades i les restrictives disposicions dels acords de confidencialitat vigents. Aquesta restricció ha sigut imperativa per mantenir la confidencialitat i la integritat de la informació confidencial.

\subsubsection{Limitació de recursos}
Les exigències computacionals dels algorismes de \textit{deep learning} són considerables, per la qual cosa requereixen grans recursos de maquinari per agilitzar els processos d'entrenament. En concret, l'ús d'unitats de processament gràfic (GPU) d'alt rendiment s'ha tornat essencial per accelerar aquest tipus de tasques. A diferència de les CPU tradicionals, l'arquitectura paral·lela de les GPU millora l'eficiència de les operacions d'alta càrrega computacional inherents als algoritmes de \textit{deep learning}. Per tant, és necessari disposar de GPU amb una potència computacional per poder entrenar i afinar la majoria dels models disponibles.

Tot i que alguns models resulten eficaços per abordar la tasca, han hagut de ser descartats a causa dels seus requisits poc pràctics en matèria de recursos tecnològics. En el context del projecte, la viabilitat de l'aplicació d'un model dins de la infraestructura disponible és molt limitant. Els models que exigien una potència de càlcul o uns excessius recursos de memòria es consideren inviables per a l'entorn d'execució del projecte.


\subsection{Comprovació dels models disponibles}
\label{sec:comparacio-models}
Avaluem cada model per valorar-ne l'eficàcia a l'hora de respondre les proves que han sigut seleccionades per cobrir els casos més típics. Aquesta secció presenta una descripció dels models que han sigut considerats, incloent-hi els punts forts i febles de cadascun. A través d'una anàlisi dels avantatges i desavantatges de cada model, l'objectiu és trobar raons per a la seva selecció o eliminació.

Per cada model, s'ha descarregat la versió més gran (i, en conseqüència, s'espera que la més efectiva), que ha permès l'equip actual. S'ha executat el model amb una sèrie de tiquets de prova depenent del tipus de tasca per la qual ha sigut entrenat. 

\begin{table}[H]
    \centering
    \begin{tabular}{|>{\centering}m{2.3cm}|>{\centering}m{1.6cm}|m{10.7cm}|}
        \hline
        \multicolumn{3}{|c|}{\textbf{Models de \textit{Question Answering}}} \\
        \hline
        \textbf{Model} & \textbf{Params.} & \textbf{Observacions} \\
        \hline
        BERT & 340M & És un model antic | Contesta meitat de la resposta \\
        BERT (fine-tuned) & 340M & Ja està afinat | Contesta meitat de la resposta \\
        RoBERTa & 355M & Millora de BERT | Contesta meitat de la resposta \\
        DeBERTaV3 & 304M & Millora de RoBERTa | Contesta meitat de la resposta \\
        GPT-2 & 774M & Massa general | Escriu altres coses \\
        BART & 406M & Més complicat d'afinar | Serveix per resumir \\
        Prometheus & 7000M & Requereix massa recursos \\
        LUKE & 483M & Resposta buida \\
        XLNet & 110M & Escriu altres coses \\
        XLNet (large) & 340M & Escriu altres coses \\
        \hline
    \end{tabular}
    \caption[Comparació dels models de \textit{Question Answering}]{Comparació dels models de \textit{Question Answering} (Resposta a preguntes)}
    \label{tab:qa-comparison}
\end{table}

\begin{table}[H]
    \centering
    \begin{tabular}{|>{\centering}m{2.3cm}|m{1.6cm}|m{10.7cm}|}
        \hline
        \multicolumn{3}{|c|}{\textbf{Models de \textit{Text Generation}}} \\
        \hline
        \textbf{Model} & \textbf{Params.} & \textbf{Observacions} \\
        \hline
        GPT-2 & 774M & Massa general | Escriu altres coses \\
        BART & 406M & Més complicat d'afinar | Serveix per resumir \\
        Prometheus & 7000M & Requereix massa recursos \\
        GoLLIE-7B & 7000M & Dissenyat per seguir instruccions | Requereix massa recursos \\
        GPT-J & 6053M & Té una versió en català | Requereix massa recursos \\
        GPT-Neo & 2700M & Té una versió en català | Entén el significat, però no contesta amb el format esperat \\
        Llama 2 & 7000M & És pitjor, en general, que Mistral 7B | Requereix massa recursos \\
        Mistral 7B & 7300M & Requereix massa recursos \\
        Mistral 7B (Instruct) & 7300M & Dissenyat per seguir instruccions | Ha sigut reduït (Quantificació) | Respon correctament \\
        Zephyr 7B $\beta$ & 7300M & Reentrenament de Mistral 7B | Requereix massa recursos \\
        Flor-Instructed & 6300M & Està dissenyat per la comprensió i escriptura de text en català, no comprèn el format de sortida \\
        Qwen1.5-Instructed & 7000M & Comprèn el català i segueix les instruccions a la perfecció. Es requereix una GPU per executar-se. \\
        \hline
    \end{tabular}
    \caption[Comparació dels models de \textit{Text Generation}]{Comparació dels models de \textit{Text Generation} (Generació de text)}
    \label{tab:tg-comparison}
\end{table}

\begin{table}[H]
    \centering
    \begin{tabular}{|>{\centering}m{2.3cm}|m{1.6cm}|m{10.7cm}|}
        \hline
        \multicolumn{3}{|c|}{\textbf{Models de \textit{Text to Text Generation}}} \\
        \hline
        \textbf{Model} & \textbf{Params.} & \textbf{Observacions} \\
        \hline
        Flan-T5-Small & 80M & No entén el significat, Serveix per tasques més petites \\
        Flan-T5-Base & 250M & És relativament petit, Contesta correctament \\
        FLAN-T5 Large & 780M & Contesta correctament \\
        FLAN-T5 XL & 3B & Massa gran per ser entrenat, Contesta correctament \\
        M2M100 & 418M & Massa complicat d'afinar, Serveix per traduir \\
        Flan-T5-Base (QA) & 300M & Reentrenat específicament per contestar preguntes, Contesta meitat de la resposta  \\
        \hline
    \end{tabular}
    \caption[Comparació dels models de \textit{Text to Text Generation}]{Comparació dels models de \textit{Text to Text Generation} (Generació de text a text)}
    \label{tab:t2t-comparison}
\end{table}