\section{Estat de l'art}
En aquesta secció es revisa l'estat de l'art dels models que poden solucionar el problema plantejat. Per aconseguir la millor solució, s'ha proposat mantenir un rang de cerca ampli, i considerar moltes propostes que en un principi no havien sigut plantejades.
\subsection{Aplicacions comercials}
Lògicament, un model de generació del llenguatge natural pot ser una eina molt potent si es busca el propòsit adequat. És per això, que moltes empreses han decidit invertir en aquest sector per assolir aquests models tan potents. Aquests models són, generalment, l'estat de l'art en aquest àmbit, ja que disposen de molts recursos per obtenir el millor resultat possible. A continuació es presenten els models comercialitzats més importants en l'àmbit global:

\begin{itemize}
  \item \textbf{GPT-4:} \textit{GPT-4} és un gran model multimodal que pot agafar entrades d'imatge i text i produir sortides de text. Representa el darrer avenç en la investigació d'\textit{OpenAI} sobre l'ampliació del \textit{deep learning}. El seu principal ús és per crear xatbots (bots conversacionals) generals, que poden conversar sobre temes molt diversos i, fins i tot, cercar a la xarxa per aportar informació extra. Alguns exemples són \textit{ChatGPT} i \textit{Bing Chat}, tots dos són serveis en línia i, per tant, no aplicables per al projecte.
  \item \textbf{LaMDA:} \textit{LaMDA} és una col·lecció de grans models lingüístics desenvolupats per Google que treballen conjuntament per resoldre diverses tasques de generació de text. \textit{LaMDA} no està disponible públicament i només es pot accedir utilitzant la seva plataforma. Google va integrar aquest model en alguns dels seus productes, per millorar la seva funcionalitat i també va desenvolupar una primera versió d'un xatbot (\textit{Google Bard}) que durant un temps va usar aquest model.
  \item \textbf{PaLM 2:} \textit{PaLM 2} és un gran model lingüístic (LLM) que amplia el llegat de Google en matèria d'aprenentatge automàtic i de recerca responsable de la IA. S'ha entrenat en un corpus divers i multilingüe de text, codi, matemàtiques i pàgines web i va ser usat durant un temps com a xatbot amb \textit{Google Bard}. Tot i que no és de codi obert, es pot accedir a PaLM 2 a través d'una API.
  \item \textbf{Gemini:} \textit{Gemini} de Google és un ambiciós projecte d'intel·ligència artificial. És gran model de llenguatge (LLM) que tingui la capacitat de fer una gran varietat de tasques, incloses les relacionades amb text, imatges i àudio. \textit{Gemini} compta amb un disseny multimodal que permet la integració de diversos tipus d'informació i dona lloc a una àmplia gamma de formats de sortida. No és una plataforma de codi obert, per la qual cosa el codi i les dades no són accessibles al públic. Per altra banda, s'integra amb eines d'IA per a la generació de continguts, com ara la versió més nova de \textit{Google Bard}, que permet la interacció de l'usuari amb aquest model.
  \item \textbf{Claude 2:} \textit{Claude 2} és un model de llenguatge d'intel·ligència artificial avançat desenvolupat per \textit{Anthropic} amb un enfocament a IA segura i beneficiosa. Permet generar textos de primera qualitat i contextualment apropiats per a diverses aplicacions, com ara la generació de codi, l'anàlisi de textos i la redacció de composicions. És accessible al públic mitjançant un lloc web beta (en forma de xatbot), però el codi i les dades utilitzades per la formació i el funcionament no són accessibles pel públic.
  \item \textbf{Inflection-1:} \textit{Inflection-1} és un gran model de llenguatge (LLM) desenvolupat per \textit{Inflection AI}. És la base de \textit{Pi}, un assistent d'IA que pretén ser un xatbot de companyia, que continua les converses més llargues amb els usuaris i s'adapta a cadascun d'ells en funció d'aquestes converses. \textit{Inflection-1} no està disponible públicament i només és accessible en línia a través del xatbot que fa servir.
  \item \textbf{Grok-1:} \textit{Grok-1} va ser creat per \textit{xAI}. Es tracta del motor que impulsa \textit{Grok}, un xatbot capaç de respondre gairebé qualsevol dubte i fins i tot d'oferir suggeriments sobre les preguntes que s'han de formular. \textit{Grok} està configurat per assistir als usuaris amb la xarxa social que del que és propietari el mateix fundador de l'empresa. \textit{Grok-1} no és un model de codi obert i no es pot emprar de manera lliure a excepció d'una beta oberta.
\end{itemize}

\subsection{Propostes descartades}
El procés de selecció del model va exigir una avaluació acurada de múltiples candidats per garantir la seva adequació als objectius del projecte. El fet de considerar tants models, cadascun amb els seus punts forts i febles, ha implicat inevitablement un rebuig de molts d'ells per trobar la solució que millor s'adeqüi al problema. 

Seguint aquestes directrius, s'ha intentat aconseguir una avaluació exhaustiva i imparcial dels models candidats. En última instància, s'han triat les opcions més adequades per complir els objectius del projecte, alhora que es treballa dins de les limitacions imposades per la sensibilitat de les dades i els recursos computacionals. La secció següent aprofundeix en les raons que van portar a descartar determinats models durant la fase de recerca.

\subsubsection{Resolució inadequada d'extreure informació}
Un dels principals criteris de selecció d'un model ha sigut la seva capacitat per extreure les paraules adequades del text que se li ofereix. Els models que no han complert una prova base que representa l'ús que se li donarà al model són exclosos immediatament. 

La prova en qüestió es basa en, donat un tiquet d'exemple, fer una pregunta o formular una frase, de manera que la continuació sempre sigui una frase que estigui continguda en el text. Aquesta prova s'ha modificat depenent de per quina tasca està entrenat cada model. Això ha servit per descartar directament els models menys adequats i quedar-se amb el que són capaços de contestar correctament, permetent entrenar només aquells que ja anaven encaminats.

\subsubsection{Accessibilitat en línia i restriccions dels acords de confidencialitat}
Alguns models han sigut eliminats a causa de la seva accessibilitat només en línia, cosa que no s'ajusta al marc del projecte, que requereix un funcionament \textit{in situ} sense dependència de servidors externs. És inviable emprar models que exigeixin la transferència de dades fora dels servidors controlats, atesa la sensibilitat de les dades i les restrictives disposicions dels acords de confidencialitat vigents. Aquesta restricció ha sigut imperativa per mantenir la confidencialitat i la integritat de la informació confidencial.

\subsubsection{Limitació de recursos}
Les exigències computacionals dels algorismes de \textit{deep learning} són considerables, per la qual cosa requereixen grans recursos de maquinari per agilitzar els processos d'entrenament. En concret, l'ús d'unitats de processament gràfic (GPU) d'alt rendiment s'ha tornat essencial per accelerar aquest tipus de tasques. A diferència de les CPU tradicionals, l'arquitectura paral·lela de les GPU millora l'eficiència de les operacions d'alta càrrega computacional inherents als algoritmes de \textit{deep learning}. Per tant, és necessari disposar de GPU amb una potència computacional per poder entrenar i afinar la majoria dels models disponibles.

Tot i que alguns models resulten eficaços per abordar la tasca, han hagut de ser descartats a causa dels seus requisits poc pràctics en matèria de recursos tecnològics. En el context del projecte, la viabilitat de l'aplicació d'un model dins de la infraestructura disponible és molt limitant. Els models que exigien una potència de càlcul o uns excessius recursos de memòria es consideren inviables per a l'entorn d'execució del projecte.


\subsection{Comprovació dels models disponibles}
Avaluem cada model per valorar-ne l'eficàcia a l'hora de respondre les proves que han sigut seleccionades per cobrir els casos més típics. Aquesta secció presenta una descripció dels models que han sigut considerats, incloent-hi els punts forts i febles de cadascun. A través d'una anàlisi dels avantatges i desavantatges de cada model, l'objectiu és trobar raons per a la seva selecció o eliminació.

Per cada model, s'ha descarregat la versió més gran (i, en conseqüència, s'espera que la més efectiva), que ha permès l'equip actual. S'ha executat el model amb una sèrie de tiquets de prova depenent del tipus de tasca per la qual ha sigut entrenat. 

\begin{table}[H]
  \centering
  \begin{tabular}{|>{\centering}m{2.3cm}|>{\centering}m{1.6cm}|m{10.7cm}|}
    \hline
    \multicolumn{3}{|c|}{\textbf{Models de \textit{Question Answering}}} \\
    \hline
    \textbf{Model} & \textbf{Params.} & \textbf{Observacions} \\
    \hline
    BERT & 340M & És un model antic | Contesta meitat de la resposta \\
    BERT (fine-tuned) & 340M & Ja està afinat | Contesta meitat de la resposta \\
    RoBERTa & 355M & Millora de BERT | Contesta meitat de la resposta \\
    DeBERTaV3 & 304M & Millora de RoBERTa | Contesta meitat de la resposta \\
    GPT-2 & 774M & Massa general | Escriu altres coses \\
    BART & 406M & Més complicat d'afinar | Serveix per resumir \\
    Prometheus & 7000M & Requereix massa recursos \\
    LUKE & 483M & Resposta buida \\
    XLNet & 110M & Escriu altres coses \\
    XLNet (large) & 340M & Escriu altres coses \\
    \hline
  \end{tabular}
  \caption{Comparació dels models de \textit{Question Answering} (Resposta a preguntes)}
  \label{tab:qa-comparison}
\end{table}

\begin{table}[H]
  \centering
  \begin{tabular}{|>{\centering}m{2.3cm}|m{1.6cm}|m{10.7cm}|}
    \hline
    \multicolumn{3}{|c|}{\textbf{Models de \textit{Text Generation}}} \\
    \hline
    \textbf{Model} & \textbf{Params.} & \textbf{Observacions} \\
    \hline
    GPT-2 & 774M & Massa general | Escriu altres coses \\
    BART & 406M & Més complicat d'afinar | Serveix per resumir \\
    Prometheus & 7000M & Requereix massa recursos \\
    GoLLIE-7B & 7000M & Dissenyat per seguir instruccions | Requereix massa recursos \\
    GPT-J & 6053M & Té una versió en català | Requereix massa recursos \\
    GPT-Neo & 2700M & Té una versió en català | Entèn el significat però no contesta amb el format esperat \\
    Llama 2 & 7000M & És pitjor, en general, que Mistral 7B | Requereix massa recursos \\
    Mistral 7B & 7300M & Requereix massa recursos \\
    Mistral 7B (Instruct) & 7300M & Dissenyat per seguir instruccions | Ha sigut reduït (Quantificació) | Respon correctament \\
    Zephyr 7B $\beta$ & 7300M & Reentrenament de Mistral 7B | Requereix massa recursos \\
    \hline
  \end{tabular}
  \caption{Comparació dels models de \textit{Text Generation} (Generació de text)}
  \label{tab:tg-comparison}
\end{table}

\begin{table}[H]
  \centering
  \begin{tabular}{|>{\centering}m{2.3cm}|m{1.6cm}|m{10.7cm}|}
    \hline
    \multicolumn{3}{|c|}{\textbf{Models de \textit{Text to Text Generation}}} \\
    \hline
    \textbf{Model} & \textbf{Params.} & \textbf{Observacions} \\
    \hline
    Flan-T5-Small & 80M & No entèn el significat, Serveix per tasques més petites \\
    Flan-T5-Base & 250M & És relativament petit, Contesta correctament \\
    FLAN-T5 Large & 780M & Contesta correctament \\
    FLAN-T5 XL & 3B & Massa gran com per ser entrenat, Contesta correctament \\
    M2M100 & 418M & Massa complicat d'afinar, Serveix per traduir \\
    Flan-T5-Base (QA) & 300M & Reentrenat específicament per contestar preguntes, Contesta meitat de la resposta  \\
    \hline
  \end{tabular}
  \caption{Comparació dels models de \textit{Text to Text Generation} (Generació de text a text)}
  \label{tab:t2t-comparison}
\end{table}

\subsection{Models destacats}
De la comparació dels models anteriors n'hi ha uns quants que han destacat per sobre dels altres. Aquests models han continuat per les proves de selecció i han sigut sotmesos a més testos i a afinaments per quantificar el seu rendiment. D'aquesta manera, es pot escollir el model més adequat pel projecte de manera acurada.

\subsubsection{Mistral 7B (Instruct)}
\textit{Mistral 7B Instruct} \cite{mistral} és un model del llenguatge natural que està afinat a partir del model \textit{Mistral 7B}. Aquest reentrenament es va realitzar, segons expliquen els creadors, per demostrar la facilitat que té el model original per adaptar-se a qualsevol tasca. Aquesta és una de les raons que va cridar molt l'atenció aquest model.

Un altre motiu pel qual aquest model és tan interessant és que afirma ser el millor model de la seva mida. Això ha sigut comprovar comparant aquest model amb els més populars de la seva categoria en els \textit{datasets} més populars.

El problema que té aquest model és que té massa paràmetres i tardaria massa temps a ser afinat correctament. De fet, el model sencer no es pot fer servir a les màquines disponibles, havent de recórrer a la versió quantificada del model per poder fer la inferència. 

Aquest model s'ha executat més concretament utilitzant el programa \textit{localGPT} \cite{localgpt}. El programa permet, en essència, parlar a un assistent sobre un document indicat. \textit{LocalGPT} primer ingereix un document i després deixa fer preguntes sobre el document, tenint l'habilitat de comprendre'l, llegir-lo i extreure informació per contestar tots els dubtes. A més a més, pot recordar el context de la conversació, el que significa que es poden fer preguntes encadenades fent referència a les anteriors respostes.

En les proves, ha donat molt bons resultats, encertant en gairebé totes les preguntes. El seu temps d'execució és bastant lent, però acceptable pels objectius que es plantegen. Finalment, aquest model s'ha descartat, ja que no es pot assegurar que les màquines de l'\textbf{Agència} tinguin la capacitat per executar aquest model.


\subsubsection{Llama 2}
\textit{Llama 2} \cite{llama} és un model NLP de codi obert desenvolupat per \textit{Meta}. Aquest model va ser publicat afirmant ser el millor model durant el seu temps en moltes proves de rendiment. Té $7000M$ paràmetres, fent impossible la seva execució localment amb els dispositius disponibles. Per aquest motiu, s'executa la seva versió quantificada. Dona resultats acceptables, però lluny de ser la solució del problema i, molt inferior comparat amb \textit{Mistral 7B}, el seu principal competidor.

Aquest model també és compatible amb el programa \textit{LocalGPT} \cite{localgpt} i, és per això i per la seva mida similar que és tan comparat amb el model \textit{Mistral 7B}. \textit{Llama 2} és el model que està seleccionat per defecte al programa \textit{localGPT}, i per aquesta raó va ser el primer a ser provat. En veure la millora significativa comparat amb el seu model competidor, va ser ràpidament substituït per aquesta versió millorada seva.


\subsubsection{Flan-T5-Base}
El model \textit{Flan-T5-Base} \cite{flan-t5} és un model de processament del llenguatge natural que presenta millores en tots els aspectes respecte al seu model previ: \textit{T5 Base}. Els seus desenvolupadors van escriure: "Amb T5, proposem reformular totes les tasques de NLP en un format unificat de text a text on l'entrada i la sortida són sempre cadenes de text, a diferència dels models d'estil BERT que només poden donar com a sortida una etiqueta de classe o un tram de l'entrada. El nostre marc de text a text ens permet utilitzar el mateix model, funció de pèrdua i hiperparàmetres en qualsevol tasca NLP."

Un punt important d'aquest model és que està entrenat amb 60 llenguatges. Això significa que té una comprensió molt gran de tots els texts que se li puguin donar. A la vegada, no interessa tant que entengui gaires idiomes, ja que el format d'entrada estarà molt centrat en un idioma.

Durant els experiments, ha demostrat una capacitat de comprensió del llenguatge i del tiquet. El principal problema és que, en la majoria dels casos, no compleix correctament l'objectiu especificat, a excepció d'una tasca en concret. Gràcies al potencial que s'ha vist en el model, es continua el procés, afinant el model amb una tasca de NER.

L'afinament ha finalitzat satisfactòriament aportant un \textit{rouge1} de $0,96$. Fent proves amb inferència s'ha vist que aquest model contesta correctament a la majoria, però ha fallat sobretot perquè repeteix més d'una vegada les respostes.

\subsubsection{Flan-T5-Small}
\textit{Flan-T5-Small} \cite{flan-t5} és el germà més petit de la família \textit{Flan-T5}. Tenint això en compte, és lògic pensar que donaria un pitjor rendiment que els altres models. El raonament darrere de la decisió de provar aquest model a fons és aconseguir un model que seria més ràpid, tant en entrenament com en inferència, a canvi de perdre poca precisió en les respostes.

Aquest model, tal com s'havia vist, té la capacitat de formular frases senzilles, però en una primera instància no ha sigut capaç de respondre cap pregunta correctament. Després de l'afinament, s'ha comprovat que no ha assolit trobar els patrons més bàsics de les dades, donant així un resultat negatiu i descartant el model per futurs passos.

\subsubsection{Flan-T5-Small (LaMini)}
El model \textit{Flan-T5-Small (LaMini)} \cite{flan-t5} \cite{lamini} és una versió afinada del model \textit{Flan-T5-Small} amb el \textit{dataset} per a seguir instruccions \textit{LaMini}. Amb aquest afinament, el model és capaç de millorar respecte al model del qual ha partit. Els creadors afirmen que té el millor rendiment general donat la seva mida.

Malauradament, no s'ha notat cap millora respecte al model anterior. No només no ha sigut capaç de generar text relacionat amb el text donat sinó que no ha contestat a les preguntes seguint el format amb el qual ha sigut entrenat. Deguts aquests motius, i veient que és el model més potent de la seva categoria, ha quedat clar que és necessari més paràmetres per poder completar aquesta tasca correctament.

\subsubsection{Flan-T5-Base (LaMini)}
Repetint el mateix procés que amb la seva versió inferior, \textit{Flan-T5-Base (LaMini)} \cite{flan-t5} \cite{lamini} és la versió afinada del model \textit{Flan-T5-Base} amb el \textit{dataset} per a seguir instruccions \textit{LaMini}. A causa dels bons resultats reportats pels mateixos creadors, amb un augment del rendiment en totes les proves comparatives, es decideix afinar aquest model, en cerca d'un rendiment superior als resultats obtinguts al \textit{Flan-T5-Base}.

El descens sorprenent del rendiment observat durant la prova del model \textit{Flan-T5-Base (LaMini)} per a la resolució d'una tasca específica, malgrat el seu èxit previ en el seguiment general d'instruccions, planteja diverses causes potencials per a aquest resultat inesperat:

\begin{itemize}
  \item \textbf{Qualitat del model:} El conjunt de dades \textit{LaMini} pot tenir característiques perjudicials per al rendiment a la tasca entrenada. Atès que el \textit{LaMini dataset} ha sigut generat sintèticament, és possible que no capturi amb precisió la complexitat i els matisos dels escenaris del món real per a dur a terme correctament les proves en qüestió. La naturalesa sintètica de les dades podria introduir biaixos o patrons poc realistes que afectin negativament la capacitat del model per generalitzar ara la tasca específica.
  \item \textbf{Rendiments decreixents a l'afinament:} L'ajust repetitiu del model pot haver resultat en un ajust excessiu, disminuint-ne l'adaptabilitat durant les proves. Els múltiples cicles d'afinament podrien haver trobat inicialment els patrons més rellevants, de manera que quan s'ha ajustat per última vegada, oferiria millores limitades i introduiria soroll potencialment. Tot i destacar en tasques generals de seguiment d'instruccions, el conjunt de dades \textit{LaMini} pot no ajustar-se als requisits específics de la tasca.
\end{itemize}

% \subsubsection{Flan-T5 Large}

% \subsection{Justificació de la tria}
